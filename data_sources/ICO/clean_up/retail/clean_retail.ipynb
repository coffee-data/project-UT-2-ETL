{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into pandas dataframe.\n",
    "df = pd.read_csv('trans_retail_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calendar years</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>European Union</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Belgium</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Cyprus</th>\n",
       "      <th>Czech Republic</th>\n",
       "      <th>Denmark</th>\n",
       "      <th>Finland</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>United Kingdom 1</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Norway</th>\n",
       "      <th>Russian Federation</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.90</td>\n",
       "      <td>3.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.43</td>\n",
       "      <td>10.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.72</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.29</td>\n",
       "      <td>10.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.88</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>2.46</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.11</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.62</td>\n",
       "      <td>3.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.94</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.65</td>\n",
       "      <td>8.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.57</td>\n",
       "      <td>2.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.27</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>11.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.69</td>\n",
       "      <td>3.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Calendar years  Unnamed: 1  European Union     Austria     Belgium  \\\n",
       "0            1990         NaN             NaN        4.90        3.27   \n",
       "1            1991         NaN             NaN        4.57        2.92   \n",
       "2            1992         NaN             NaN        4.99        3.05   \n",
       "3            1993         NaN             NaN        4.97        2.78   \n",
       "4            1994         NaN             NaN        4.58        3.42   \n",
       "\n",
       "      Bulgaria     Cyprus     Czech Republic     Denmark     Finland  ...  \\\n",
       "0          NaN       2.83                NaN        3.81        2.98  ...   \n",
       "1          NaN       2.80                NaN        3.67        2.72  ...   \n",
       "2          NaN       2.87                NaN        3.79        2.46  ...   \n",
       "3          NaN       2.60                NaN        3.48        1.94  ...   \n",
       "4          NaN       3.18                NaN        4.45        2.73  ...   \n",
       "\n",
       "      Slovenia     Spain     Sweden     United Kingdom 1  Unnamed: 26  Japan  \\\n",
       "0          NaN      3.62       3.43                10.55          NaN  10.26   \n",
       "1          NaN      3.50       3.29                10.41          NaN  11.88   \n",
       "2          NaN      3.50       3.11                10.09          NaN  12.62   \n",
       "3          NaN      2.79       2.65                 8.44          NaN  14.57   \n",
       "4          NaN      2.76       3.79                11.36          NaN  14.69   \n",
       "\n",
       "   Norway  Russian Federation  Switzerland   USA  \n",
       "0    3.31                 NaN         4.83  2.97  \n",
       "1    3.16                 NaN         4.36  2.81  \n",
       "2    3.12                 NaN         4.52  2.58  \n",
       "3    2.46                 NaN         4.27  2.47  \n",
       "4    3.29                 NaN         4.50  3.40  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek Analysis\n",
    "It is immediately evident the transpose in excel created some minor problems: \n",
    "\n",
    "(a) the data set contains columns intended for naming elements in sets (i.e. 'European Union').\n",
    "\n",
    "(b) there are unnamed rows with nothing in them.\n",
    "\n",
    "(c) there are columns with names appended 1 (i.e. Malta 1) which represent special types of coffee (soluble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calendar years           int64\n",
       "Unnamed: 1             float64\n",
       "European Union         float64\n",
       "   Austria             float64\n",
       "   Belgium             float64\n",
       "   Bulgaria            float64\n",
       "   Cyprus              float64\n",
       "   Czech Republic      float64\n",
       "   Denmark             float64\n",
       "   Finland             float64\n",
       "   France              float64\n",
       "   Germany             float64\n",
       "   Hungary             float64\n",
       "   Italy               float64\n",
       "   Latvia              float64\n",
       "   Lithuania           float64\n",
       "   Luxembourg          float64\n",
       "   Malta 1             float64\n",
       "   Netherlands         float64\n",
       "   Poland              float64\n",
       "   Portugal            float64\n",
       "   Slovakia            float64\n",
       "   Slovenia            float64\n",
       "   Spain               float64\n",
       "   Sweden              float64\n",
       "   United Kingdom 1    float64\n",
       "Unnamed: 26            float64\n",
       "Japan                  float64\n",
       "Norway                 float64\n",
       "Russian Federation     float64\n",
       "Switzerland            float64\n",
       "USA                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dtypes look clean\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = list(df.columns)\n",
    "df.columns = df.columns.str.replace(\"   \",\"\")\n",
    "df.columns = df.columns.str.replace(\" 1\",\".1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "### Investigating columns\n",
    "#### Observations\n",
    "1. Unnamed and other problem columns have dtype int64 but actually contain NaNs.\n",
    "    \n",
    "    a. We will want to drop Unnamed columns but keep columns referencing coffee type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Unnamed:.1', 'Unnamed: 26']\n"
     ]
    }
   ],
   "source": [
    "# Get column names and turn into a list for iteration\n",
    "cols = list(df.columns)\n",
    "\n",
    "count = 0\n",
    "lst_garb = []\n",
    "\n",
    "# Count and print list of unwanted column names\n",
    "for col in cols:\n",
    "    if \"Unnamed\" in col:\n",
    "        count += 1\n",
    "        lst_garb.append(col)\n",
    "        \n",
    "print(count)\n",
    "print(lst_garb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 dropped df cols\n",
    "df1 = df.drop(columns=lst_garb)\n",
    "df1.head()\n",
    "len(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        $----(Good Series)----$\n",
      "        Calendar years : 0\n",
      "        \n",
      "\n",
      "        #----(Region Category)----#\n",
      "        European Union : 29\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Austria : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Belgium : 5\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Bulgaria : 12\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Cyprus : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Czech Republic : 7\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Denmark : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Finland : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        France : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Germany : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Hungary : 4\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Italy : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Latvia : 3\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Lithuania : 7\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Luxembourg : 10\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Malta.1 : 5\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Netherlands : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Poland : 5\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Portugal : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Slovakia : 7\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Slovenia : 10\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Spain : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Sweden : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        United Kingdom.1 : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Japan : 0\n",
      "        \n",
      "\n",
      "        $----(Good Series)----$\n",
      "        Norway : 0\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Russian Federation : 20\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        Switzerland : 11\n",
      "        \n",
      "\n",
      "        x----(Missing Values)----x\n",
      "        USA : 1\n",
      "        \n",
      "\n",
      "=====\n",
      "Summary\n",
      "-----\n",
      "30 total columns.\n",
      "\n",
      "1 columns to drop.\n",
      "14 columns with missing data.\n",
      "15 columns with complete data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign cols with new df1 columns\n",
    "cols = df1.columns\n",
    "\n",
    "# 29 rows of data expected\n",
    "exp_row = len(df1.index)\n",
    "\n",
    "# Empty lists for iteration and appending\n",
    "lst_col_drop = []\n",
    "lst_col_miss = ['Calendar years']\n",
    "lst_col_good = []\n",
    "\n",
    "# Set of lists to create a df for missing\n",
    "lst_key_miss = []\n",
    "lst_val_miss = []\n",
    "\n",
    "# Collect columns with missing data for a dataframe\n",
    "lst_dict_miss = []\n",
    "\n",
    "for idx, col in enumerate(cols):\n",
    "    count_na = 0\n",
    "    for row in df1[col]:\n",
    "        if row == '' or pd.isnull(row):\n",
    "            count_na += 1\n",
    "            \n",
    "    # Country has any missing values append\n",
    "    if count_na > 0 and count_na < exp_row: \n",
    "        key = col\n",
    "        val = count_na\n",
    "        \n",
    "        lst_key_miss.append(key)\n",
    "        lst_val_miss.append(val)\n",
    "        \n",
    "        lst_col_miss.append(col)\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        x{'-'*4}(Missing Values){'-'*4}x\n",
    "        {key} : {val}\n",
    "        \"\"\")\n",
    "        \n",
    "    # Column only has missing values append\n",
    "    if count_na == exp_row:\n",
    "        key = col\n",
    "        val = count_na\n",
    "        \n",
    "        lst_col_drop.append(col)\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        #{'-'*4}(Region Category){'-'*4}#\n",
    "        {key} : {val}\n",
    "        \"\"\")\n",
    "    \n",
    "    # Country has no missing values append\n",
    "    if count_na == 0:\n",
    "        key = col\n",
    "        val = count_na\n",
    "        \n",
    "        lst_col_good.append(col)\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ${'-'*4}(Good Series){'-'*4}$\n",
    "        {key} : {val}\n",
    "        \"\"\")\n",
    "\n",
    "    \n",
    "print(f\"\"\"\n",
    "=====\n",
    "Summary\n",
    "-----\n",
    "{len(cols)} total columns.\n",
    "\n",
    "{len(lst_col_drop)} columns to drop.\n",
    "{len(lst_key_miss)} columns with missing data.\n",
    "{len(lst_col_good)} columns with complete data.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====\n",
    "Summary\n",
    "-----\n",
    "30 total columns.\n",
    "\n",
    "1 columns to drop.\n",
    "14 columns with missing data.\n",
    "15 columns with complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign regions with missing values to df\n",
    "df_missing_list = pd.DataFrame(data=({\n",
    "    'Country': lst_key_miss, \n",
    "    'Missing_Rows': lst_val_miss\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df record of missing rows with counts by region\n",
    "df_missing_list = df_missing_list.sort_values('Missing_Rows', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# df of complete data \n",
    "df_good = df1[lst_col_good]\n",
    "\n",
    "# df of columns with missing data\n",
    "df_missing = df1[lst_col_miss]\n",
    "\n",
    "# df of columns dropped that contained header info\n",
    "df_drop = df1[lst_col_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluble extraction for complete data\n",
    "# Get column names and turn into a list for iteration\n",
    "\n",
    "def extract_sol(df,string):\n",
    "    f\"\"\"\n",
    "    Takes in dataframe, checks column names against substring,\n",
    "    and filters and drops.\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = list(df.columns)\n",
    "\n",
    "    count = 0\n",
    "    lst = []\n",
    "\n",
    "    # Count and print list of unwanted column names\n",
    "    for col in cols:\n",
    "        if string in col:\n",
    "            count += 1\n",
    "            lst.append(col)\n",
    "\n",
    "    print(count)\n",
    "    print(lst)\n",
    "\n",
    "    # Drop soluble\n",
    "    df.drop(columns=(lst))\n",
    "    return df\n",
    "\n",
    "def store_sol(df,string):\n",
    "    f\"\"\"\n",
    "    Takes in dataframe, checks column names against substring,\n",
    "    and filters and drops.\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = list(df.columns)\n",
    "\n",
    "    count = 0\n",
    "    lst = []\n",
    "\n",
    "    # Count and print list of unwanted column names\n",
    "    for col in cols:\n",
    "        if string in col:\n",
    "            count += 1\n",
    "            lst.append(col)\n",
    "\n",
    "    print(count)\n",
    "    print(lst)\n",
    "\n",
    "    return df[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['United Kingdom.1']\n"
     ]
    }
   ],
   "source": [
    "df_good = extract_sol(df_good,\".1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['Malta.1']\n"
     ]
    }
   ],
   "source": [
    "df_missing = extract_sol(df_missing,\".1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_good.join(df_missing, lsuffix='_dup')\n",
    "df_join_col = pd.DataFrame(list(df_join.columns), columns=['Country'])\n",
    "df_join_col.to_csv('retail_col_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_missing_list.to_csv('retail_missing_data_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Calendar_years', 'Austria', 'Cyprus', 'Denmark', 'Finland', 'France',\n",
       "       'Germany', 'Italy', 'Netherlands', 'Portugal', 'Spain', 'Sweden',\n",
       "       'United_Kingdom.1', 'Japan', 'Norway'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = df_good.columns\n",
    "\n",
    "res = [sub.replace(' ', '_') for sub in list] \n",
    "df_good.columns = res \n",
    "df_good.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good.to_csv('retail_complete_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing.to_csv('retail_missing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.to_csv('ret_orginal_category_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
